{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Weather\n",
    "\n",
    "Mengyu Jackson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Business Problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pprint\n",
    "import time\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, Perceptron, PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier, NearestCentroid\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import KNNImputer, SimpleImputer, IterativeImputer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.impute import MissingIndicator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherAUS = pd.read_csv('./data/weatherAUS.csv')\n",
    "df = weatherAUS.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                 0\n",
       "Location             0\n",
       "MinTemp           1485\n",
       "MaxTemp           1261\n",
       "Rainfall          3261\n",
       "Evaporation      62790\n",
       "Sunshine         69835\n",
       "WindGustDir      10326\n",
       "WindGustSpeed    10263\n",
       "WindDir9am       10566\n",
       "WindDir3pm        4228\n",
       "WindSpeed9am      1767\n",
       "WindSpeed3pm      3062\n",
       "Humidity9am       2654\n",
       "Humidity3pm       4507\n",
       "Pressure9am      15065\n",
       "Pressure3pm      15028\n",
       "Cloud9am         55888\n",
       "Cloud3pm         59358\n",
       "Temp9am           1767\n",
       "Temp3pm           3609\n",
       "RainToday         3261\n",
       "RainTomorrow      3267\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weatherAUS.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Day'] = df['Date'].dt.day\n",
    "df.pop('Date')\n",
    "df = df.dropna(subset=['RainToday', 'RainTomorrow'])\n",
    "df['RainToday'] = df['RainToday'].replace('No', 0).replace('Yes', 1).astype(float)\n",
    "df['RainTomorrow'] = df['RainTomorrow'].replace('No', 0).replace('Yes', 1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WindGustDir'] = df['WindGustDir'].fillna(\"NaN\")\n",
    "df['WindDir9am'] = df['WindDir9am'].fillna(\"NaN\")\n",
    "df['WindDir3pm'] = df['WindDir3pm'].fillna(\"NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer([\n",
    "    (\"windgustdir\",OneHotEncoder(), [\"WindGustDir\"]),\n",
    "    (\"winddir9am\",OneHotEncoder(), [\"WindDir9am\"]),\n",
    "    (\"winddir3pm\",OneHotEncoder(), [\"WindDir3pm\"]),\n",
    "    (\"loc\",OneHotEncoder(), [\"Location\"]),], \n",
    "    remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140787"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = df.dropna()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df[df['Year']>=2016]\n",
    "y_test = x_test.pop('RainTomorrow')\n",
    "x_train = df[df['Year']<2016]\n",
    "y_train = x_train.pop('RainTomorrow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('windgustdir', OneHotEncoder(),\n",
       "                                 ['WindGustDir']),\n",
       "                                ('winddir9am', OneHotEncoder(), ['WindDir9am']),\n",
       "                                ('winddir3pm', OneHotEncoder(), ['WindDir3pm']),\n",
       "                                ('loc', OneHotEncoder(), ['Location'])])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_transformer.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = pd.DataFrame(data=column_transformer.transform(x_train).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Model\n",
    "\n",
    "* RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfc = make_pipeline(column_transformer, \n",
    "#                     FunctionTransformer(lambda x: x.todense(), accept_sparse=True),\n",
    "#                     MinMaxScaler(),\n",
    "#                     KNNImputer(), \n",
    "#                     RandomForestClassifier())\n",
    "# rfc.fit(x_train, y_train)\n",
    "# rfc.score(x_test, y_test)\n",
    "\n",
    "\n",
    "# Score is 0.8453908984830805"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7945546479968884"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = make_pipeline(column_transformer, \n",
    "                    MaxAbsScaler(),\n",
    "                    SimpleImputer(), \n",
    "                    KNeighborsClassifier())\n",
    "rfc.fit(x_train, y_train)\n",
    "rfc.score(x_test, y_test)\n",
    "#rfc=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB (0.5497801303863525 seconds): 0.7530143912874367\n",
      "DecisionTreeClassifier (21.280158281326294 seconds): 0.773123298327499\n",
      "BaggingClassifier (150.1186318397522 seconds): 0.8358615324776352\n",
      "RandomForestClassifier (223.84542393684387 seconds): 0.8471022948269156\n",
      "ExtraTreesClassifier (439.9449441432953 seconds): 0.847024504084014\n",
      "AdaBoostClassifier (8.627912521362305 seconds): 0.8387008945935434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier (1029.1785008907318 seconds): 0.8369117075068067\n",
      "{'AdaBoostClassifier': {'classifier': Pipeline(steps=[('columntransformer',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('windgustdir',\n",
      "                                                  OneHotEncoder(),\n",
      "                                                  ['WindGustDir']),\n",
      "                                                 ('winddir9am', OneHotEncoder(),\n",
      "                                                  ['WindDir9am']),\n",
      "                                                 ('winddir3pm', OneHotEncoder(),\n",
      "                                                  ['WindDir3pm']),\n",
      "                                                 ('loc', OneHotEncoder(),\n",
      "                                                  ['Location'])])),\n",
      "                ('maxabsscaler', MaxAbsScaler()),\n",
      "                ('simpleimputer', SimpleImputer()),\n",
      "                ('adaboostclassifier', AdaBoostClassifier())]),\n",
      "                        'score': 0.8387008945935434,\n",
      "                        'training_time': 8.627912521362305},\n",
      " 'BaggingClassifier': {'classifier': Pipeline(steps=[('columntransformer',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('windgustdir',\n",
      "                                                  OneHotEncoder(),\n",
      "                                                  ['WindGustDir']),\n",
      "                                                 ('winddir9am', OneHotEncoder(),\n",
      "                                                  ['WindDir9am']),\n",
      "                                                 ('winddir3pm', OneHotEncoder(),\n",
      "                                                  ['WindDir3pm']),\n",
      "                                                 ('loc', OneHotEncoder(),\n",
      "                                                  ['Location'])])),\n",
      "                ('maxabsscaler', MaxAbsScaler()),\n",
      "                ('simpleimputer', SimpleImputer()),\n",
      "                ('baggingclassifier', BaggingClassifier())]),\n",
      "                       'score': 0.8358615324776352,\n",
      "                       'training_time': 150.1186318397522},\n",
      " 'BernoulliNB': {'classifier': Pipeline(steps=[('columntransformer',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('windgustdir',\n",
      "                                                  OneHotEncoder(),\n",
      "                                                  ['WindGustDir']),\n",
      "                                                 ('winddir9am', OneHotEncoder(),\n",
      "                                                  ['WindDir9am']),\n",
      "                                                 ('winddir3pm', OneHotEncoder(),\n",
      "                                                  ['WindDir3pm']),\n",
      "                                                 ('loc', OneHotEncoder(),\n",
      "                                                  ['Location'])])),\n",
      "                ('maxabsscaler', MaxAbsScaler()),\n",
      "                ('simpleimputer', SimpleImputer()),\n",
      "                ('bernoullinb', BernoulliNB())]),\n",
      "                 'score': 0.7530143912874367,\n",
      "                 'training_time': 0.5497801303863525},\n",
      " 'DecisionTreeClassifier': {'classifier': Pipeline(steps=[('columntransformer',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('windgustdir',\n",
      "                                                  OneHotEncoder(),\n",
      "                                                  ['WindGustDir']),\n",
      "                                                 ('winddir9am', OneHotEncoder(),\n",
      "                                                  ['WindDir9am']),\n",
      "                                                 ('winddir3pm', OneHotEncoder(),\n",
      "                                                  ['WindDir3pm']),\n",
      "                                                 ('loc', OneHotEncoder(),\n",
      "                                                  ['Location'])])),\n",
      "                ('maxabsscaler', MaxAbsScaler()),\n",
      "                ('simpleimputer', SimpleImputer()),\n",
      "                ('decisiontreeclassifier', DecisionTreeClassifier())]),\n",
      "                            'score': 0.773123298327499,\n",
      "                            'training_time': 21.280158281326294},\n",
      " 'ExtraTreesClassifier': {'classifier': Pipeline(steps=[('columntransformer',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('windgustdir',\n",
      "                                                  OneHotEncoder(),\n",
      "                                                  ['WindGustDir']),\n",
      "                                                 ('winddir9am', OneHotEncoder(),\n",
      "                                                  ['WindDir9am']),\n",
      "                                                 ('winddir3pm', OneHotEncoder(),\n",
      "                                                  ['WindDir3pm']),\n",
      "                                                 ('loc', OneHotEncoder(),\n",
      "                                                  ['Location'])])),\n",
      "                ('maxabsscaler', MaxAbsScaler()),\n",
      "                ('simpleimputer', SimpleImputer()),\n",
      "                ('extratreesclassifier', ExtraTreesClassifier())]),\n",
      "                          'score': 0.847024504084014,\n",
      "                          'training_time': 439.9449441432953},\n",
      " 'MLPClassifier': {'classifier': Pipeline(steps=[('columntransformer',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('windgustdir',\n",
      "                                                  OneHotEncoder(),\n",
      "                                                  ['WindGustDir']),\n",
      "                                                 ('winddir9am', OneHotEncoder(),\n",
      "                                                  ['WindDir9am']),\n",
      "                                                 ('winddir3pm', OneHotEncoder(),\n",
      "                                                  ['WindDir3pm']),\n",
      "                                                 ('loc', OneHotEncoder(),\n",
      "                                                  ['Location'])])),\n",
      "                ('maxabsscaler', MaxAbsScaler()),\n",
      "                ('simpleimputer', SimpleImputer()),\n",
      "                ('mlpclassifier', MLPClassifier())]),\n",
      "                   'score': 0.8369117075068067,\n",
      "                   'training_time': 1029.1785008907318},\n",
      " 'RandomForestClassifier': {'classifier': Pipeline(steps=[('columntransformer',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('windgustdir',\n",
      "                                                  OneHotEncoder(),\n",
      "                                                  ['WindGustDir']),\n",
      "                                                 ('winddir9am', OneHotEncoder(),\n",
      "                                                  ['WindDir9am']),\n",
      "                                                 ('winddir3pm', OneHotEncoder(),\n",
      "                                                  ['WindDir3pm']),\n",
      "                                                 ('loc', OneHotEncoder(),\n",
      "                                                  ['Location'])])),\n",
      "                ('maxabsscaler', MaxAbsScaler()),\n",
      "                ('simpleimputer', SimpleImputer()),\n",
      "                ('randomforestclassifier', RandomForestClassifier())]),\n",
      "                            'score': 0.8471022948269156,\n",
      "                            'training_time': 223.84542393684387}}\n"
     ]
    }
   ],
   "source": [
    "classifier_dict = {}\n",
    "\n",
    "for classifier in [\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(),\n",
    "    Perceptron(),\n",
    "    PassiveAggressiveClassifier(),\n",
    "    #NuSVC(nu=0.2),\n",
    "    LinearSVC(),\n",
    "    SVC(),\n",
    "    KNeighborsClassifier(),\n",
    "    #RadiusNeighborsClassifier(radius=1.5), # Nothing found in radius, even after increase\n",
    "    NearestCentroid(),\n",
    "    #MultinomialNB(), Negative values?\n",
    "    BernoulliNB(),\n",
    "    DecisionTreeClassifier(),\n",
    "    BaggingClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    ExtraTreesClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    MLPClassifier(),\n",
    "]:\n",
    "    start = time.time()\n",
    "    pipeline = make_pipeline(column_transformer, \n",
    "                    MaxAbsScaler(),\n",
    "                    SimpleImputer(), \n",
    "                    classifier)\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    score = pipeline.score(x_test, y_test)\n",
    "    training_time = time.time() - start\n",
    "    print(f\"{type(classifier).__name__} ({training_time} seconds): {score}\")\n",
    "    classifier_dict[type(classifier).__name__] = {\"classifier\": pipeline, \"score\": score, \"training_time\": training_time}\n",
    "\n",
    "pprint.pprint(classifier_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier (1703.0184400081635 seconds): 0.8081680280046675\n",
      "{'MLPClassifier': {'classifier': Pipeline(steps=[('columntransformer',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('windgustdir',\n",
      "                                                  OneHotEncoder(),\n",
      "                                                  ['WindGustDir']),\n",
      "                                                 ('winddir9am', OneHotEncoder(),\n",
      "                                                  ['WindDir9am']),\n",
      "                                                 ('winddir3pm', OneHotEncoder(),\n",
      "                                                  ['WindDir3pm']),\n",
      "                                                 ('loc', OneHotEncoder(),\n",
      "                                                  ['Location'])])),\n",
      "                ('maxabsscaler', MaxAbsScaler()),\n",
      "                ('simpleimputer', SimpleImputer()),\n",
      "                ('mlpclassifier',\n",
      "                 MLPClassifier(activation='tanh', max_iter=2000,\n",
      "                               solver='lbfgs'))]),\n",
      "                   'score': 0.8081680280046675,\n",
      "                   'training_time': 1703.0184400081635}}\n"
     ]
    }
   ],
   "source": [
    "classifier_dict = {}\n",
    "\n",
    "for classifier in [\n",
    "    MLPClassifier(activation=\"tanh\", solver=\"lbfgs\", max_iter=2000),\n",
    "]:\n",
    "    start = time.time()\n",
    "    pipeline = make_pipeline(column_transformer, \n",
    "                    MaxAbsScaler(),\n",
    "                    SimpleImputer(), \n",
    "                    classifier)\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    score = pipeline.score(x_test, y_test)\n",
    "    raining_time = time.time() - start\n",
    "    print(f\"{type(classifier).__name__} ({training_time} seconds): {score}\")\n",
    "    classifier_dict[type(classifier).__name__] = {\"classifier\": pipeline, \"score\": score, \"training_time\": training_time}\n",
    "\n",
    "pprint.pprint(classifier_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_dict[\"RandomForestClassifier\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc = make_pipeline(column_transformer, LogisticRegression(random_state=0))\n",
    "lrc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drc = make_pipeline(column_transformer, DecisionTreeClassifier(random_state=0))\n",
    "drc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drc.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model\n",
    "\n",
    "## Linear Model Feature Engineering\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Models\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
